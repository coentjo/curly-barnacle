{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heavily inspired by the lesson \n",
    "https://learn.deeplearning.ai/langchain-chat-with-your-data/lesson/2/document-loading\n",
    "I want to:\n",
    "1. Get the contents of a git repo with lesson material (in github-pages).\n",
    "2. Add the files with content (for now only the markdown files) and create a vector store.\n",
    "3. Be able to chat with the material, ask questions like: 'Tell me about the concept blablathisnthat ...', or 'Ask a question about ...'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These should already be handled by the requirements.txt\n",
    "#!pip install python-dotenv\n",
    "#!pip install pypdf \n",
    "#!pip install markdown\n",
    "#!pip install openai\n",
    "#!pip install GitPython\n",
    "#!pip install bs4\n",
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "\n",
    "langchain.verbose = True\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "#loader = PyPDFLoader(\"samples/tutorial_Class.pdf\")\n",
    "pdfLoader = PyPDFLoader(\"samples/tutorial_Class.pdf\")\n",
    "pages = pdfLoader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative: url to a markdown file\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "webLoader = WebBaseLoader(\"https://github.com/basecamp/handbook/blob/master/37signals-is-you.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='St√©phane Ducasse, Lukas Renggli, David C. Shaffer, Rick Zacconewith Michael DaviesDynamic WebDevelopmentwith', metadata={'source': 'samples/tutorial_Class.pdf', 'page': 0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '.git_softwarematerial'...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Git Clone \n",
    "import subprocess\n",
    "\n",
    "repo_url = \"https://github.com/stasemsoft/softwarematerial.git\"\n",
    "local_dir = \".git_softwarematerial\"\n",
    "\n",
    "subprocess.check_call([\"git\", \"clone\", repo_url, local_dir])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('.git_softwarematerial/README.md'),\n",
       " PosixPath('.git_softwarematerial/objects.md'),\n",
       " PosixPath('.git_softwarematerial/docs/legacy/Explanation-Array-Lists.md'),\n",
       " PosixPath('.git_softwarematerial/docs/legacy/readme.md.md')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "repo_path = pathlib.Path(local_dir)\n",
    "markdown_files = list(repo_path.glob(\"**/*.md\"))\n",
    "markdown_files[0:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "# 1 embedding to put all text in. \n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "\n",
    "\n",
    "def SplitMarkdownText(markdown_text,embeddings):\n",
    "    md_header_splits = markdown_splitter.split_text(markdown_text)\n",
    "    print(f\"1.{type(md_header_splits)}\")\n",
    "    for item in md_header_splits:\n",
    "        print(f\"2.{type(item)}\")\n",
    "        embedding.append(embedding.embed_query(item))\n",
    "    print(np.dot(embeddings[0:], embeddings[:0]))\n",
    "    return md_header_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "\n",
    "for markdown_file in markdown_files[0:3]:\n",
    "    with open(markdown_file, \"r\") as f:\n",
    "        print(\"--file--------------------\")\n",
    "        content = f.read()\n",
    "        # chunk = SplitMarkdownText(content,embeddings) # inlined here: \n",
    "        # --- \n",
    "        md_header_splits = markdown_splitter.split_text(content)\n",
    "        aDoc = md_header_splits[0]\n",
    "        x = embedding.embed_query(aDoc.page_content)\n",
    "        embeddings.append(x)\n",
    "        print(np.dot(embeddings[0:], embeddings[:0]))\n",
    "        # --- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embs = OpenAIEmbeddings()\n",
    "text = \"sample Q\"\n",
    "doc = Document(page_content=text)\n",
    "query_result = embs.embed_query(doc)\n",
    "\n",
    "print(len(query_result))\n",
    "\n",
    "# Seems that the principle works here, but I don't have a paid version, os my quotum does not allow me to *really* try it. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
